{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow.keras as K\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.optimizers as optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from minisom import MiniSom\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r\"...\\tox21_dense_train.csv\"\n",
    "data = pd.read_csv(PATH).values\n",
    "labels = pd.read_csv(PATH).columns\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(799):\n",
    "    if max(data[:, 3:][:, x])!=min(data[:, 3:][:, x]):\n",
    "        xtr = (data[:, 3:][:, x]-np.mean(data[:, 3:][:, x]))/(max(data[:, 3:][:, x])-min(data[:, 3:][:, x]))\n",
    "        data[:, 3:][:, x] = xtr\n",
    "    else:\n",
    "        xtr = (data[:, 3:][:, x])/(max(data[:, 3:][:, x])+min(data[:, 3:][:, x])+1e-10)+0.5\n",
    "        data[:, 3:][:, x] = xtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[:, 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = np.array(data[:10000], dtype=\"float32\")\n",
    "xvalid = np.array(data[10000:12000], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 20\n",
    "c = 20\n",
    "iter = 5000\n",
    "sigma = 1\n",
    "lr = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "som = MiniSom(x= r, y=c, input_len=799, sigma=sigma, learning_rate=lr)\n",
    "som.random_weights_init(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "som.train_random(xtrain, iter, verbose=1)\n",
    "elapsed = time.time()-start\n",
    "print(elapsed, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each neuron represents a cluster\n",
    "winner_coordinates = np.array([som.winner(x) for x in xtrain]).T\n",
    "# with np.ravel_multi_index we convert the bidimensional\n",
    "# coordinates to a monodimensional index\n",
    "cluster_index = np.ravel_multi_index(winner_coordinates, [r,c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# plotting the clusters using the first 2 dimentions of the data\n",
    "for c in np.unique(cluster_index):\n",
    "    plt.scatter(xtrain[cluster_index == c, 0],\n",
    "                xtrain[cluster_index == c, 1], label='cluster='+str(c), alpha=.7)\n",
    "\n",
    "# plotting centroids\n",
    "for centroid in som.get_weights():\n",
    "    plt.scatter(centroid[:, 0], centroid[:, 1], marker='x', \n",
    "                s=80, linewidths=5, color='k', label='centroid')\n",
    "plt.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cabed6552182076907bfdc495182d8bb0133da97d0d21fa33aa63cdbe2263e8f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
