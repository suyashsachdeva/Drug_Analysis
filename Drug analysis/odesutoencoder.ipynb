{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim \n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "from torchmetrics import Accuracy \n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "from tqdm.auto import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preporcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'AW', 'AWeight', 'Arto', 'BertzCT', 'Chi0', 'Chi1',\n",
       "       'Chi10', 'Chi2', 'Chi3',\n",
       "       ...\n",
       "       'W3D', 'W3DH', 'WNSA1', 'WNSA2', 'WNSA3', 'WPSA1', 'WPSA2', 'WPSA3',\n",
       "       'grav', 'rygr'],\n",
       "      dtype='object', length=802)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = r\"C:\\Users\\suyash\\Desktop\\toxic\\tox21_dense_train.csv\"\n",
    "data = pd.read_csv(PATH).values\n",
    "labels = pd.read_csv(PATH).columns\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(799):\n",
    "    if max(data[:, 3:][:, x])!=min(data[:, 3:][:, x]):\n",
    "        xtr = (data[:, 3:][:, x]-np.mean(data[:, 3:][:, x]))/(max(data[:, 3:][:, x])-min(data[:, 3:][:, x]))\n",
    "        data[:, 3:][:, x] = xtr\n",
    "    else:\n",
    "        xtr = (data[:, 3:][:, x])/(max(data[:, 3:][:, x])+min(data[:, 3:][:, x])+1e-10)+0.5\n",
    "        data[:, 3:][:, x] = xtr\n",
    "data = data[:, 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suyash\\AppData\\Local\\Temp/ipykernel_29528/986131156.py:7: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  xtrain = np.array([x for x in DataLoader(torch.from_numpy(xtrain), batch_size=BATCH_SIZE)], dtype=\"object\")\n",
      "C:\\Users\\suyash\\AppData\\Local\\Temp/ipykernel_29528/986131156.py:8: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  xvalid = np.array([x for x in DataLoader(torch.from_numpy(xvalid), batch_size=VALID_SIZE)], dtype=\"object\")\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "VALID_SIZE = 100\n",
    "\n",
    "xtrain = np.array(data[:10000], dtype=\"float32\")\n",
    "xvalid = np.array(data[10000:12000], dtype=\"float32\")\n",
    "\n",
    "xtrain = np.array([x for x in DataLoader(torch.from_numpy(xtrain), batch_size=BATCH_SIZE)], dtype=\"object\")\n",
    "xvalid = np.array([x for x in DataLoader(torch.from_numpy(xvalid), batch_size=VALID_SIZE)], dtype=\"object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try later\n",
    "delaring parameters like this is not possible because i thik the __init__ function declared layers are used to determine the number of parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DenseBlock(nn.Module):\n",
    "#     def __init__(self, inp, out):\n",
    "#         super(DenseBlock, self).__init__()\n",
    "#         self.dense = nn.Linear(inp, out)\n",
    "#         self.batchnorm = nn.BatchNorm1d(out, momentum=0.9)\n",
    "#         self.relu = nn.ReLU()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.relu(self.batchnorm(self.dense(x)))\n",
    "\n",
    "# class Autoencoder(nn.Module):\n",
    "#     def __init__(self, inpdim, ndim:list):\n",
    "#         super(Autoencoder, self).__init__()\n",
    "#         ndim.insert(0, inpdim)\n",
    "#         self.block = []\n",
    "\n",
    "#         for n in range(len(ndim)-1):\n",
    "#             self.block.append(DenseBlock(ndim[n], ndim[n+1]))\n",
    "#         self.block.append(DenseBlock(ndim[-1], 1))\n",
    "\n",
    "#         ndim.reverse()\n",
    "#         self.block.append(DenseBlock(1, ndim[0]))\n",
    "#         for n in range(len(ndim)-1):\n",
    "#             self.block.append(DenseBlock(ndim[n], ndim[n+1]))\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         for b in self.block:\n",
    "#             x = b(x)\n",
    "#         return x\n",
    "\n",
    "# model = Autoencoder(799, [300,100,30,10,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, inp, out):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(inp, out)\n",
    "        self.batchnorm = nn.BatchNorm1d(out, momentum=0.9)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(self.batchnorm(self.dense(x)))\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, inp) -> None:\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.den1 = DenseBlock(inp, 300)\n",
    "        self.den2 = DenseBlock(300, 100)\n",
    "        self.den3 = DenseBlock(100, 30)\n",
    "        self.den4 = DenseBlock(30, 10)\n",
    "        self.den5 = DenseBlock(10, 3)\n",
    "        self.den6 = DenseBlock(3, 1)\n",
    "        self.den7 = DenseBlock(1, 3)\n",
    "        self.den8 = DenseBlock(3, 10)\n",
    "        self.den9 = DenseBlock(10, 30)\n",
    "        self.den10 = DenseBlock(30, 100)\n",
    "        self.den11 = DenseBlock(100, 300)\n",
    "        self.den12 = DenseBlock(300, inp)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.den12(self.den11(self.den10(self.den9(self.den8(self.den7(self.den6(self.den5(self.den4(self.den3(self.den2(self.den1(x))))))))))))\n",
    "\n",
    "model = Autoencoder(799)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100 || Loss: 0.06823854148387909 || Validation Loss: 0.015857389196753502\n",
      "\n",
      "Epoch: 2/100 || Loss: 0.008190597407519817 || Validation Loss: 0.009160177782177925\n",
      "\n",
      "Epoch: 3/100 || Loss: 0.007698947563767433 || Validation Loss: 0.02889552339911461\n",
      "\n",
      "Epoch: 4/100 || Loss: 0.010018164291977882 || Validation Loss: 0.008611990138888359\n",
      "\n",
      "Epoch: 5/100 || Loss: 0.007197219878435135 || Validation Loss: 0.022047845646739006\n",
      "\n",
      "Epoch: 6/100 || Loss: 0.007167369592934847 || Validation Loss: 0.01650538481771946\n",
      "\n",
      "Epoch: 7/100 || Loss: 0.007158719934523106 || Validation Loss: 0.015683161094784737\n",
      "\n",
      "Epoch: 8/100 || Loss: 0.007157500367611647 || Validation Loss: 0.0156710185110569\n",
      "\n",
      "Epoch: 9/100 || Loss: 0.00715735275298357 || Validation Loss: 0.015669669955968857\n",
      "\n",
      "Epoch: 10/100 || Loss: 0.0071573443710803986 || Validation Loss: 0.015669722110033035\n",
      "\n",
      "Epoch: 11/100 || Loss: 0.007157343439757824 || Validation Loss: 0.015669725835323334\n",
      "\n",
      "Epoch: 12/100 || Loss: 0.007157343439757824 || Validation Loss: 0.015669725835323334\n",
      "\n",
      "Epoch: 13/100 || Loss: 0.007157343439757824 || Validation Loss: 0.015669725835323334\n",
      "\n",
      "Epoch: 14/100 || Loss: 0.007157343439757824 || Validation Loss: 0.015669725835323334\n",
      "\n",
      "Epoch: 15/100 || Loss: 0.007157343439757824 || Validation Loss: 0.015669725835323334\n",
      "\n",
      "Epoch: 16/100 || Loss: 0.007157343439757824 || Validation Loss: 0.015669725835323334\n",
      "\n",
      "Epoch: 17/100 || Loss: 0.007157343439757824 || Validation Loss: 0.015669725835323334\n",
      "\n",
      "Epoch: 18/100 || Loss: 0.007157343439757824 || Validation Loss: 0.015669725835323334\n",
      "\n",
      "Epoch: 19/100 || Loss: 0.007157343439757824 || Validation Loss: 0.015669725835323334\n",
      "\n",
      "Epoch: 20/100 || Loss: 0.007157343439757824 || Validation Loss: 0.015669725835323334\n",
      "\n",
      "Epoch: 21/100 || Loss: 0.007157343439757824 || Validation Loss: 0.015669725835323334\n",
      "\n",
      "Epoch: 22/100 || Loss: 0.007157343439757824 || Validation Loss: 0.015669725835323334\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29528/2698523536.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mlss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlss\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[1;31m# acc = accuracy(xpred, xtr)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\suyash\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\suyash\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\suyash\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    155\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'step'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m             adam(params_with_grad,\n\u001b[0m\u001b[0;32m    158\u001b[0m                  \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m                  \u001b[0mexp_avgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\suyash\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m     func(params,\n\u001b[0m\u001b[0;32m    214\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\suyash\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[0;32m    303\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m                 \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m             \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "steps = len(xtrain)\n",
    "vstep = len(xvalid)\n",
    "epochs = 100\n",
    "criterian = nn.MSELoss()\n",
    "learning_rate = 1e-3\n",
    "decay = 1\n",
    "accuracy = Accuracy()\n",
    "for epoch in range(epochs):\n",
    "    vls = 0\n",
    "    lss = 0\n",
    "    learning_rate = learning_rate/(1+epoch*decay)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    for step in range(steps):\n",
    "        xtr = xtrain[step]\n",
    "\n",
    "        xpred = model(xtr)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterian(xpred, xtr)\n",
    "        lss = lss+loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # acc = accuracy(xpred, xtr)\n",
    "\n",
    "    for step in range(vstep):\n",
    "        vtr = xvalid[step]\n",
    "\n",
    "        xpred = model(vtr)\n",
    "        vloss = criterian(xpred, vtr)\n",
    "        vls = vls + vloss\n",
    "        # vac = accuracy(xpred, vtr)\n",
    "\n",
    "    print(f\"Epoch: {epoch+1}/{epochs} || Loss: {lss/steps} || Validation Loss: {vls/vstep}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cabed6552182076907bfdc495182d8bb0133da97d0d21fa33aa63cdbe2263e8f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
