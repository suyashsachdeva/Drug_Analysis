{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.optimizers as optim\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r'.../tox21_dense_train.csv'\n",
    "data = pd.read_csv(PATH).values\n",
    "labels = pd.read_csv(PATH).columns\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(799):\n",
    "    if max(data[:, 3:][:, x])!=min(data[:, 3:][:, x]):\n",
    "        xtr = (data[:, 3:][:, x]-np.mean(data[:, 3:][:, x]))/(max(data[:, 3:][:, x])-min(data[:, 3:][:, x]))\n",
    "        data[:, 3:][:, x] = xtr\n",
    "    else:\n",
    "        xtr = (data[:, 3:][:, x])/(max(data[:, 3:][:, x])+min(data[:, 3:][:, x])+1e-10)+0.5\n",
    "        data[:, 3:][:, x] = xtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[:, 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = np.array(data[:10000], dtype=\"float32\")\n",
    "xvalid = np.array(data[10000:12000], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DenseBlock(x, ndim):\n",
    "    x = layers.Dense(ndim)(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    x = layers.BatchNormalization(momentum=0.9)(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    return  x\n",
    "\n",
    "def autoencoder(inp):\n",
    "    inp = layers.Input(inp)\n",
    "    x = DenseBlock(inp, 100)\n",
    "    enc_out = DenseBlock(x, 12)\n",
    "    x = DenseBlock(enc_out, 100)\n",
    "    dec_out = DenseBlock(x, 799)\n",
    "    encoder = models.Model(inputs=inp, outputs=enc_out, name=\"Encoder\")\n",
    "    model = models.Model(inputs=inp, outputs=dec_out, name=\"Autoencoder\")\n",
    "\n",
    "    return encoder, model\n",
    "\n",
    "encoder, model = autoencoder((799))\n",
    "print(encoder.summary())\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=optim.Adam(learning_rate=1e-4), metrics=\"accuracy\")\n",
    "model.fit(xtrain, xtrain, batch_size=100, verbose=1, epochs=200, validation_data=[xvalid, xvalid], validation_batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"./model50.h5\")\n",
    "# encoder.save(\"./encoder50.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minisom import MiniSom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 4\n",
    "c = 3\n",
    "iter = 50000\n",
    "sigma = 1\n",
    "lr = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "som = MiniSom(x=r, y=c, input_len=12, sigma=sigma, learning_rate=lr)\n",
    "xsom = encoder(xtrain)\n",
    "som.random_weights_init(xsom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "som.train_random(xsom, iter, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each neuron represents a cluster\n",
    "winner_coordinates = np.array([som.winner(x) for x in xsom]).T\n",
    "# with np.ravel_multi_index we convert the bidimensional\n",
    "# coordinates to a monodimensional index\n",
    "cluster_index = np.ravel_multi_index(winner_coordinates, [r,c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# # plotting the clusters using the first 2 dimentions of the data\n",
    "# for c in np.unique(cluster_index):\n",
    "#     plt.scatter(xsom[cluster_index == c, 0],\n",
    "#                 xsom[cluster_index == c, 1], label='cluster='+str(c), alpha=.7)\n",
    "\n",
    "# # plotting centroids\n",
    "# for centroid in som.get_weights():\n",
    "#     plt.scatter(centroid[:, 0], centroid[:, 1], marker='x', \n",
    "#                 s=80, linewidths=5, color='k', label='centroid')\n",
    "# plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('Sab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "edcbdc4d886d2a44df5355e1013a050975e64a8a5e81397d04c2253b5ba5d091"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
