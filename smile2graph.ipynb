{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf \n",
    "# import tensorflow.keras.layers as layers\n",
    "# import tensorflow.keras.models as models\n",
    "# import tensorflow.keras.optimizers as optim\n",
    "\n",
    "# import spektral as sp \n",
    "# import spektral.layers as SL\n",
    "# import spektral.data.graph as graph\n",
    "# import spektral.data.loaders as loaders\n",
    "\n",
    "import torch as th\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch_geometric as thg\n",
    "import torch_geometric.nn as gnn\n",
    "import torch_geometric.nn.functional as gf\n",
    "from torch_geometric.data import Data, HeteroData\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils.convert import from_scipy_sparse_matrix as keys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rdkit, rdkit.Chem, rdkit.Chem.rdDepictor, rdkit.Chem.Draw\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DENSE = r\".../tox21_dense_train.csv\"\n",
    "LABEL = r\"...\\tox21_labels_train.csv\"\n",
    "SMILE = r\"...\\nr-ar.smiles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_elements = {6: \"C\", 8: \"O\", 1: \"H\", 17: \"Cl\", 7: \"N\", 9: \"F\", 16: \"S\",\n",
    "               35: \"Br\", 14: \"Si\", 11: \"Na\", 53: \"I\", 80: \"Hg\", 5: \"B\", \n",
    "               19: \"K\", 15: \"P\", 79: \"Au\", 24: \"Cr\", 50: \"Sn\", 20: \"Ca\",\n",
    "               48: \"Cd\", 30: \"Zn\", 23: \"V\", 33: \"As\", 3: \"Li\", 29: \"Cu\",\n",
    "               27:\"Co\", 47: \"Ag\", 34: \"Se\", 78: \"Pt\", 83: \"Bi\", 26: \"Fe\", \n",
    "               51: \"Sb\", 12: \"Mg\", 13: \"Al\", 81: \"Tl\", 56: \"Ba\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smiles2graph(sml):\n",
    "    \"\"\"Argument for the RD2NX function should be a valid SMILES sequence\n",
    "    returns: the graph\n",
    "    \"\"\"\n",
    "    m = rdkit.Chem.MolFromSmiles(sml)\n",
    "    m = rdkit.Chem.AddHs(m)\n",
    "    order_string = {\n",
    "        rdkit.Chem.rdchem.BondType.SINGLE: 1,\n",
    "        rdkit.Chem.rdchem.BondType.DOUBLE: 2,\n",
    "        rdkit.Chem.rdchem.BondType.TRIPLE: 3,\n",
    "        rdkit.Chem.rdchem.BondType.AROMATIC: 4,\n",
    "    }\n",
    "    N = len(list(m.GetAtoms()))\n",
    "    nodes = np.zeros((N, len(my_elements)))\n",
    "    lookup = list(my_elements.keys())\n",
    "    for i in m.GetAtoms():\n",
    "        nodes[i.GetIdx(), lookup.index(i.GetAtomicNum())] = 1\n",
    "\n",
    "    adj = np.zeros((N, N, 5))\n",
    "    for j in m.GetBonds():\n",
    "        u = min(j.GetBeginAtomIdx(), j.GetEndAtomIdx())\n",
    "        v = max(j.GetBeginAtomIdx(), j.GetEndAtomIdx())\n",
    "        order = j.GetBondType()\n",
    "        if order in order_string:\n",
    "            order = order_string[order]\n",
    "        else:\n",
    "            raise Warning(\"Ignoring bond order\" + order)\n",
    "        adj[u, v, order] = 1\n",
    "        adj[v, u, order] = 1\n",
    "    return nodes, adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(SMILE, 'r')\n",
    "smile = file.read().split('\\n')\n",
    "xtrain = []\n",
    "ytrain = []\n",
    "\n",
    "for c, x in enumerate(smile):\n",
    "    try:\n",
    "        x = x.split('\\t')\n",
    "        if x[2]=='1' or c%20==0:\n",
    "            nodes, adj= smiles2graph(x[0])\n",
    "            adj_mat = np.sum(adj, axis=-1) + np.eye(adj.shape[0])\n",
    "            degree = np.sum(adj_mat, axis=-1)\n",
    "            new_nodes = np.einsum(\"i,ij,jk->ik\", 1 / degree, adj_mat, nodes)\n",
    "            # print(new_nodes.shape, adj_mat.shape)\n",
    "            xtrain.append(Data(x=th.tensor(th.from_numpy(new_nodes), dtype=th.float32), edge_index=th.tensor(adj_mat, dtype=th.long).nonzero().t().contiguous()))\n",
    "            ytrain.append(x[2])\n",
    "    except:\n",
    "        pass\n",
    "ytrain = th.from_numpy(np.array(ytrain, dtype=\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [x for x in DataLoader(xtrain, batch_size=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Should work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, in_dim=36, hidden_dim=64):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.conv1 = gnn.GraphConv(in_dim, hidden_dim)\n",
    "        self.conv2 = gnn.GraphConv(hidden_dim, hidden_dim)\n",
    "        self.conv3 = gnn.GraphConv(hidden_dim, hidden_dim*2)\n",
    "        self.conv4 = gnn.GraphConv(hidden_dim*2, hidden_dim*2)\n",
    "        self.pool  = gnn.MeanAggregation()\n",
    "        self.dense = nn.Linear(hidden_dim*2, hidden_dim)\n",
    "        self.classify = nn.Linear(hidden_dim,1)\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        # Apply graph convolution and activation.\n",
    "        h = F.relu(self.conv1(h, g))\n",
    "        h = F.relu(self.conv2(h, g))\n",
    "        h = F.relu(self.conv3(h, g))\n",
    "        h = F.relu(self.conv4(h, g))\n",
    "        h = self.pool(h)\n",
    "        h = F.relu(self.dense(h))\n",
    "        return F.sigmoid(self.classify(h))\n",
    "        \n",
    "\n",
    "model = Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(y_true, y_prob):\n",
    "    assert y_true.size() == y_prob.size()\n",
    "    y_prob = y_prob > 0.5\n",
    "    return (y_true == y_prob).sum().item() / y_true.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "criterian = nn.BCELoss()\n",
    "learning_rate = 1e-4\n",
    "decay = 1e-2\n",
    "for epoch in range(epochs):\n",
    "    lss = 0\n",
    "    acc = 0\n",
    "    learning_rate = learning_rate/(epoch*decay+1)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    for step, (xtr, ytr) in enumerate(zip(dataset, ytrain)):\n",
    "        h = xtr.x\n",
    "        g = th.tensor(xtr.edge_index, dtype=th.long)\n",
    "        batch = xtr.batch\n",
    "        optimizer.zero_grad()\n",
    "        ypred = model(g,h)\n",
    "        loss = criterian(ypred, ytr.reshape(-1,1))\n",
    "\n",
    "        if ypred>0.5 and ytr>0.5:\n",
    "            acc=acc+1\n",
    "        elif ypred<=0.5 and ytr<=0.5:\n",
    "            acc=acc+1\n",
    "        # print(ypred, ytr)\n",
    "        lss = lss+loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch: {epoch+1}/{epochs} || Loss: {lss/(step+1):.4f} || Accuracy: {acc/(step+1):.4f} \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 ('graph': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e067a7d41aaecea2c3cb96f2320fd4300af65f2300805fdda9e01e34a6b5804"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
