{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.optimizers as optim\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'AW', 'AWeight', 'Arto', 'BertzCT', 'Chi0', 'Chi1',\n",
       "       'Chi10', 'Chi2', 'Chi3',\n",
       "       ...\n",
       "       'W3D', 'W3DH', 'WNSA1', 'WNSA2', 'WNSA3', 'WPSA1', 'WPSA2', 'WPSA3',\n",
       "       'grav', 'rygr'],\n",
       "      dtype='object', length=802)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = r'/Users/suyashsachdeva/Desktop/GyanBhandar/tox21_dense_train.csv'\n",
    "data = pd.read_csv(PATH).values\n",
    "labels = pd.read_csv(PATH).columns\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(799):\n",
    "    if max(data[:, 3:][:, x])!=min(data[:, 3:][:, x]):\n",
    "        xtr = (data[:, 3:][:, x]-np.mean(data[:, 3:][:, x]))/(max(data[:, 3:][:, x])-min(data[:, 3:][:, x]))\n",
    "        data[:, 3:][:, x] = xtr\n",
    "    else:\n",
    "        xtr = (data[:, 3:][:, x])/(max(data[:, 3:][:, x])+min(data[:, 3:][:, x])+1e-10)+0.5\n",
    "        data[:, 3:][:, x] = xtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[:, 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = np.array(data[:10000], dtype=\"float32\")\n",
    "xvalid = np.array(data[10000:12000], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 799)]             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 256)               204800    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256)              1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 256)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 100)               25700     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 100)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 231,924\n",
      "Trainable params: 231,212\n",
      "Non-trainable params: 712\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"Autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 799)]             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 256)               204800    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256)              1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 256)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 100)               25700     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 256)               25856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 256)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 799)               205343    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 799)              3196      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 799)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 467,343\n",
      "Trainable params: 464,521\n",
      "Non-trainable params: 2,822\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def DenseBlock(x, ndim):\n",
    "    x = layers.Dense(ndim)(x)\n",
    "    x = layers.BatchNormalization(momentum=0.5)(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    return  x\n",
    "\n",
    "def autoencoder(inp):\n",
    "    inp = layers.Input(inp)\n",
    "    x = DenseBlock(inp, 256)\n",
    "    enc_out = DenseBlock(x, 100)\n",
    "    x = DenseBlock(enc_out, 256)\n",
    "    dec_out = DenseBlock(x, 799)\n",
    "    encoder = models.Model(inputs=inp, outputs=enc_out, name=\"Encoder\")\n",
    "    model = models.Model(inputs=inp, outputs=dec_out, name=\"Autoencoder\")\n",
    "\n",
    "    return encoder, model\n",
    "\n",
    "encoder, model = autoencoder((799))\n",
    "print(encoder.summary())\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1145 - accuracy: 0.1294 - val_loss: 0.0398 - val_accuracy: 0.4895\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0498 - accuracy: 0.4388 - val_loss: 0.0185 - val_accuracy: 0.4855\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0410 - accuracy: 0.4956 - val_loss: 0.0259 - val_accuracy: 0.5865\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0356 - accuracy: 0.3344 - val_loss: 0.0332 - val_accuracy: 0.4085\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0314 - accuracy: 0.2023 - val_loss: 0.0457 - val_accuracy: 0.3095\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0276 - accuracy: 0.2902 - val_loss: 0.0106 - val_accuracy: 0.4410\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0225 - accuracy: 0.3019 - val_loss: 0.0167 - val_accuracy: 0.2835\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0187 - accuracy: 0.3020 - val_loss: 0.0421 - val_accuracy: 0.3680\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0155 - accuracy: 0.3119 - val_loss: 0.0227 - val_accuracy: 0.4400\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0130 - accuracy: 0.2830 - val_loss: 0.0176 - val_accuracy: 0.3905\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0108 - accuracy: 0.2698 - val_loss: 0.0164 - val_accuracy: 0.2600\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0091 - accuracy: 0.2681 - val_loss: 0.0169 - val_accuracy: 0.3265\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0076 - accuracy: 0.2552 - val_loss: 0.0100 - val_accuracy: 0.2510\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0064 - accuracy: 0.2836 - val_loss: 0.0105 - val_accuracy: 0.2460\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0053 - accuracy: 0.2952 - val_loss: 0.0056 - val_accuracy: 0.2980\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0044 - accuracy: 0.1605 - val_loss: 0.0050 - val_accuracy: 0.0935\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0037 - accuracy: 0.1221 - val_loss: 0.0048 - val_accuracy: 0.1110\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0031 - accuracy: 0.1238 - val_loss: 0.0061 - val_accuracy: 0.1105\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0026 - accuracy: 0.2221 - val_loss: 0.0028 - val_accuracy: 0.7910\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0022 - accuracy: 0.7621 - val_loss: 0.0024 - val_accuracy: 0.7820\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.7655 - val_loss: 0.0024 - val_accuracy: 0.7725\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0017 - accuracy: 0.7677 - val_loss: 0.0027 - val_accuracy: 0.7990\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.7571 - val_loss: 0.0017 - val_accuracy: 0.7915\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0014 - accuracy: 0.7669 - val_loss: 0.0013 - val_accuracy: 0.7515\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0013 - accuracy: 0.7743 - val_loss: 0.0013 - val_accuracy: 0.7855\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0012 - accuracy: 0.7744 - val_loss: 0.0012 - val_accuracy: 0.8260\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0012 - accuracy: 0.7726 - val_loss: 0.0011 - val_accuracy: 0.7995\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0011 - accuracy: 0.7762 - val_loss: 0.0011 - val_accuracy: 0.7930\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0011 - accuracy: 0.7730 - val_loss: 0.0011 - val_accuracy: 0.7690\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0011 - accuracy: 0.7686 - val_loss: 0.0010 - val_accuracy: 0.8080\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0010 - accuracy: 0.7759 - val_loss: 9.8243e-04 - val_accuracy: 0.7810\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0010 - accuracy: 0.7817 - val_loss: 9.7350e-04 - val_accuracy: 0.7990\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 9.7856e-04 - accuracy: 0.7826 - val_loss: 9.3861e-04 - val_accuracy: 0.8285\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 9.5445e-04 - accuracy: 0.7827 - val_loss: 9.0843e-04 - val_accuracy: 0.8025\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 9.5600e-04 - accuracy: 0.7805 - val_loss: 9.0843e-04 - val_accuracy: 0.7900\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 9.3849e-04 - accuracy: 0.7832 - val_loss: 8.8138e-04 - val_accuracy: 0.8055\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 9.3749e-04 - accuracy: 0.7881 - val_loss: 9.2017e-04 - val_accuracy: 0.8030\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 9.2791e-04 - accuracy: 0.7814 - val_loss: 9.1772e-04 - val_accuracy: 0.8160\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 9.1429e-04 - accuracy: 0.7828 - val_loss: 8.3995e-04 - val_accuracy: 0.8150\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 8.8117e-04 - accuracy: 0.7846 - val_loss: 8.9933e-04 - val_accuracy: 0.8505\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 8.5172e-04 - accuracy: 0.7852 - val_loss: 8.1971e-04 - val_accuracy: 0.8110\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 8.7506e-04 - accuracy: 0.7780 - val_loss: 8.5923e-04 - val_accuracy: 0.7940\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 8.4977e-04 - accuracy: 0.7814 - val_loss: 8.0969e-04 - val_accuracy: 0.8015\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 8.5705e-04 - accuracy: 0.7823 - val_loss: 8.4917e-04 - val_accuracy: 0.7865\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 8.2903e-04 - accuracy: 0.7893 - val_loss: 8.2301e-04 - val_accuracy: 0.7900\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 8.2370e-04 - accuracy: 0.7931 - val_loss: 7.7176e-04 - val_accuracy: 0.8125\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 8.2598e-04 - accuracy: 0.7868 - val_loss: 7.7792e-04 - val_accuracy: 0.8195\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 8.1564e-04 - accuracy: 0.7903 - val_loss: 8.1188e-04 - val_accuracy: 0.8130\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 8.0142e-04 - accuracy: 0.7884 - val_loss: 7.6569e-04 - val_accuracy: 0.8190\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 7.8996e-04 - accuracy: 0.7899 - val_loss: 7.6728e-04 - val_accuracy: 0.8375\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 7.7100e-04 - accuracy: 0.7973 - val_loss: 7.7895e-04 - val_accuracy: 0.8265\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 7.8186e-04 - accuracy: 0.7940 - val_loss: 7.2494e-04 - val_accuracy: 0.8040\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 7.8273e-04 - accuracy: 0.7901 - val_loss: 7.1540e-04 - val_accuracy: 0.8150\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 7.7680e-04 - accuracy: 0.7907 - val_loss: 7.2808e-04 - val_accuracy: 0.8390\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 7.5664e-04 - accuracy: 0.7957 - val_loss: 7.2945e-04 - val_accuracy: 0.8025\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 7.4866e-04 - accuracy: 0.8001 - val_loss: 6.9910e-04 - val_accuracy: 0.8175\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 7.3840e-04 - accuracy: 0.7973 - val_loss: 6.7693e-04 - val_accuracy: 0.8280\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 7.4287e-04 - accuracy: 0.7972 - val_loss: 7.2277e-04 - val_accuracy: 0.8065\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 7.2874e-04 - accuracy: 0.7891 - val_loss: 6.8372e-04 - val_accuracy: 0.8200\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 7.3485e-04 - accuracy: 0.7983 - val_loss: 7.1010e-04 - val_accuracy: 0.8235\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 7.3519e-04 - accuracy: 0.7928 - val_loss: 7.3875e-04 - val_accuracy: 0.8435\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 6.8185e-04 - accuracy: 0.7971 - val_loss: 6.4976e-04 - val_accuracy: 0.8135\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 7.0006e-04 - accuracy: 0.7989 - val_loss: 6.6241e-04 - val_accuracy: 0.8335\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 6.8254e-04 - accuracy: 0.8004 - val_loss: 6.8574e-04 - val_accuracy: 0.8075\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 7.0240e-04 - accuracy: 0.7869 - val_loss: 6.8365e-04 - val_accuracy: 0.8365\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 6.8109e-04 - accuracy: 0.7940 - val_loss: 6.4251e-04 - val_accuracy: 0.8340\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 6.6942e-04 - accuracy: 0.7993 - val_loss: 6.5067e-04 - val_accuracy: 0.8520\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 6.7631e-04 - accuracy: 0.7973 - val_loss: 6.4197e-04 - val_accuracy: 0.8325\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 6.6014e-04 - accuracy: 0.8044 - val_loss: 6.6117e-04 - val_accuracy: 0.8325\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 6.7055e-04 - accuracy: 0.8005 - val_loss: 6.5340e-04 - val_accuracy: 0.8240\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 6.6065e-04 - accuracy: 0.8008 - val_loss: 6.4433e-04 - val_accuracy: 0.8350\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 6.4160e-04 - accuracy: 0.8040 - val_loss: 6.1110e-04 - val_accuracy: 0.8305\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 6.4601e-04 - accuracy: 0.8054 - val_loss: 6.2869e-04 - val_accuracy: 0.8335\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 6.4739e-04 - accuracy: 0.8034 - val_loss: 6.0663e-04 - val_accuracy: 0.8385\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 6.4325e-04 - accuracy: 0.8007 - val_loss: 6.1930e-04 - val_accuracy: 0.8420\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 6.1699e-04 - accuracy: 0.8075 - val_loss: 6.0890e-04 - val_accuracy: 0.8255\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 6.1457e-04 - accuracy: 0.7992 - val_loss: 6.3911e-04 - val_accuracy: 0.8405\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 6.2955e-04 - accuracy: 0.7993 - val_loss: 6.9379e-04 - val_accuracy: 0.8345\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 6.1547e-04 - accuracy: 0.7985 - val_loss: 6.2394e-04 - val_accuracy: 0.8395\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 6.0919e-04 - accuracy: 0.8030 - val_loss: 5.9994e-04 - val_accuracy: 0.8290\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 5.9816e-04 - accuracy: 0.8098 - val_loss: 5.7324e-04 - val_accuracy: 0.8380\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 5.9813e-04 - accuracy: 0.8069 - val_loss: 6.2651e-04 - val_accuracy: 0.8285\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 5.9600e-04 - accuracy: 0.8007 - val_loss: 5.5456e-04 - val_accuracy: 0.8380\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 5.9580e-04 - accuracy: 0.8064 - val_loss: 6.8050e-04 - val_accuracy: 0.8335\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 5.8811e-04 - accuracy: 0.7975 - val_loss: 5.8281e-04 - val_accuracy: 0.8315\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 5.8475e-04 - accuracy: 0.8128 - val_loss: 5.6128e-04 - val_accuracy: 0.8450\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 5.7712e-04 - accuracy: 0.8063 - val_loss: 5.3895e-04 - val_accuracy: 0.8470\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 5.7829e-04 - accuracy: 0.8081 - val_loss: 5.4182e-04 - val_accuracy: 0.8315\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 5.7743e-04 - accuracy: 0.8086 - val_loss: 5.7895e-04 - val_accuracy: 0.8410\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 5.8602e-04 - accuracy: 0.8041 - val_loss: 5.4964e-04 - val_accuracy: 0.8360\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 5.7091e-04 - accuracy: 0.8066 - val_loss: 5.6215e-04 - val_accuracy: 0.8400\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 5.6730e-04 - accuracy: 0.8000 - val_loss: 5.3708e-04 - val_accuracy: 0.8510\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 5.5485e-04 - accuracy: 0.8095 - val_loss: 5.4515e-04 - val_accuracy: 0.8610\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 5.4850e-04 - accuracy: 0.8138 - val_loss: 5.1412e-04 - val_accuracy: 0.8445\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 5.7588e-04 - accuracy: 0.8066 - val_loss: 5.3278e-04 - val_accuracy: 0.8455\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 5.5658e-04 - accuracy: 0.8047 - val_loss: 5.5082e-04 - val_accuracy: 0.8320\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 5.4266e-04 - accuracy: 0.8096 - val_loss: 5.0637e-04 - val_accuracy: 0.8490\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 5.4154e-04 - accuracy: 0.8085 - val_loss: 5.5053e-04 - val_accuracy: 0.8390\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 5.4547e-04 - accuracy: 0.8103 - val_loss: 4.9358e-04 - val_accuracy: 0.8655\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 5.4135e-04 - accuracy: 0.8027 - val_loss: 5.0024e-04 - val_accuracy: 0.8260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e4fbec70>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer=\"adam\", metrics=\"accuracy\")\n",
    "model.fit(xtrain, xtrain, batch_size=100, verbose=1, epochs=100, validation_data=[xvalid, xvalid], validation_batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model.save(\"./model.h5\")\n",
    "encoder.save(\"./encoder.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('Sab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "edcbdc4d886d2a44df5355e1013a050975e64a8a5e81397d04c2253b5ba5d091"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
